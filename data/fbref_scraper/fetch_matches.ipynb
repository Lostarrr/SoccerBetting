{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooked-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import shelve\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atomic-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures_url = {\n",
    "    'EPL': {\n",
    "        '2020-2021': \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\", \n",
    "        '2019-2020': \"https://fbref.com/en/comps/9/3232/schedule/2019-2020-Premier-League-Scores-and-Fixtures\", \n",
    "        '2018-2019': \"https://fbref.com/en/comps/9/1889/schedule/2018-2019-Premier-League-Scores-and-Fixtures\",\n",
    "        '2017-2018': \"https://fbref.com/en/comps/9/1631/schedule/2017-2018-Premier-League-Scores-and-Fixtures\", \n",
    "        '2016-2017': \"https://fbref.com/en/comps/9/1526/schedule/2016-2017-Premier-League-Scores-and-Fixtures\", \n",
    "        '2015-2016': \"https://fbref.com/en/comps/9/1467/schedule/2015-2016-Premier-League-Scores-and-Fixtures\",\n",
    "        '2014-2015': \"https://fbref.com/en/comps/9/733/schedule/2014-2015-Premier-League-Scores-and-Fixtures\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brutal-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def shelve_it(file_name):\n",
    "#     d = shelve.open(file_name)\n",
    "\n",
    "#     def decorator(func):\n",
    "#         def new_func(param):\n",
    "#             if param not in d:\n",
    "#                 d[param] = func(param)\n",
    "#             else:\n",
    "#                 print('Found Cached!')\n",
    "#             return d[param]\n",
    "\n",
    "#         return new_func\n",
    "\n",
    "#     return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spanish-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @shelve_it('matches.shelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "announced-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskcache import Cache\n",
    "\n",
    "cache = Cache(\"matches.shelve\")\n",
    "\n",
    "@cache.memoize()\n",
    "def get_page(link):\n",
    "    return requests.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turned-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPL 2020-2021\n",
      "EPL 2019-2020\n",
      "EPL 2018-2019\n",
      "EPL 2017-2018\n",
      "EPL 2016-2017\n",
      "EPL 2015-2016\n",
      "EPL 2014-2015\n"
     ]
    }
   ],
   "source": [
    "columns = {}\n",
    "datasets = {}\n",
    "\n",
    "for league in fixtures_url:\n",
    "    for season in fixtures_url[league]:\n",
    "        data = []\n",
    "        print(league, season)\n",
    "        link = fixtures_url[league][season]\n",
    "        page = get_page(link)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#         break\n",
    "        results = soup.find_all(\"div\", id=lambda value: value and value.startswith(\"div_sched\"))[0]\n",
    "        column = ['League', 'Season'] + [el.text.strip() for el in results.find('thead').find_all('th')]\n",
    "        if league not in columns:\n",
    "            columns[league] = {}\n",
    "        columns[league][season] = column\n",
    "    \n",
    "        for el in results.find('tbody').find_all('tr'):\n",
    "            row = []\n",
    "            row.append(league)\n",
    "            row.append(season)\n",
    "            count_empty = 0\n",
    "            for el2 in el.find_all('th'):\n",
    "                row.append(el2.text.strip())\n",
    "                if el2.text.strip() == '':\n",
    "                    count_empty += 1\n",
    "            for el2 in el.find_all('td'):\n",
    "                row.append(el2.text.strip())\n",
    "                if el2.text.strip() == '':\n",
    "                    count_empty += 1\n",
    "            if count_empty != (len(row) - 2):\n",
    "                data.append(row)\n",
    "                \n",
    "        if league not in datasets:\n",
    "            datasets[league] = {}\n",
    "        datasets[league][season] = data\n",
    "        \n",
    "for league in datasets:\n",
    "    for season in datasets[league]:\n",
    "        df = pd.DataFrame(datasets[league][season], columns = columns[league][season])\n",
    "        df['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')\n",
    "        df[['HomeScore', 'AwayScore']] = df['Score'].str.split('â€“',expand=True)\n",
    "        df = df.drop(['Score', 'Notes', 'Match Report'], 1)\n",
    "        df = df.rename(columns={'Home': 'HomeTeam', 'Away': 'AwayTeam'})\n",
    "        df['Attendance'] = pd.to_numeric(df['Attendance'].str.replace(',', ''), errors='coerce').astype('Int64')\n",
    "\n",
    "        if 'xG' in list(df.columns):\n",
    "            cols = list(df.columns)\n",
    "            cols[cols.index('xG')] = 'xG_Home'\n",
    "            cols[cols.index('xG')] = 'xG_Away'\n",
    "            df.columns = cols\n",
    "            df['xG_Home'] = pd.to_numeric(df['xG_Home'], errors='coerce').astype('Float64')\n",
    "            df['xG_Away'] = pd.to_numeric(df['xG_Away'], errors='coerce').astype('Float64')\n",
    "        \n",
    "        df['Wk'] = pd.to_numeric(df['Wk'].str.replace(',', ''), errors='coerce').astype('Int64')\n",
    "        df['HomeScore'] = pd.to_numeric(df['HomeScore'].str.replace(',', ''), errors='coerce').astype('Int64')\n",
    "        df['AwayScore'] = pd.to_numeric(df['AwayScore'].str.replace(',', ''), errors='coerce').astype('Int64')\n",
    "\n",
    "        path = Path(f'dfs/{league}/matches')\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        df.to_csv(os.path.join(path, f'{season}.csv'), index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
